{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1 NLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Explain One-Hot Encoding\n"
      ],
      "metadata": {
        "id": "LJJfLBfZMvrb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This algorithm is used to generate a vector for each word with length  equal to the number of distinct words in the dataset. \n",
        "\n",
        "In one hot encoding, every word (even symbols) which are part of the  given text data are written in the form of vectors, constituting only of 1  and 0 . \n",
        "This allows the word to be identified uniquely by its one hot vector and  vice versa, that is no two words will have same one hot vector  representation.\n"
      ],
      "metadata": {
        "id": "EHFHIEvTMxf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A sentence, “I love my dog”, each word in the sentence would be  represented as below: \n",
        "\n",
        "I → [1 0 0 0],  \n",
        "love → [0 1 0 0],  \n",
        "my → [0 0 1 0],  \n",
        "dog → [0 0 0 1] \n",
        "\n",
        "The entire sentence is then represented as: \n",
        "“I love my dog” = [ [1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1] ]\n"
      ],
      "metadata": {
        "id": "z-djhuD0NSs1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain Bag of Words\n"
      ],
      "metadata": {
        "id": "tR-5NUF-NnPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is one of the most widely used algorithm for Text Vectorization.\n",
        "It performs well in text classification problems.\n",
        "\n",
        "The main intuition - same types of documents will have same words\n",
        "in similar frequency."
      ],
      "metadata": {
        "id": "l811bfJaN5c8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain Bag of N-Grams\n"
      ],
      "metadata": {
        "id": "MIG4IpkYO4ws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is very similar of BoW, instead of taking one word at a time, BoN captures the\n",
        "frequency of the Ngram specified.\n",
        "BoW is a special case of ngrams it works with unigrams.\n",
        "\n",
        "The bag of words does not take into consideration the order of the words in\n",
        "which they appear in a document, and only individual words are counted.\n",
        "In some cases, the order of the words might be important.\n",
        "\n",
        "N-grams captures the context in which the words are used together. For\n",
        "example, it might be a good idea to consider bigrams like “New York” instead\n",
        "of breaking it into individual words like “New” and “York”"
      ],
      "metadata": {
        "id": "YuWbmcBIPKVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain TF-IDF\n"
      ],
      "metadata": {
        "id": "RhDxiAkKQQTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This algorithm is an improvement of the Bag of ngrams, and is widely used in\n",
        "the search technologies. Tf-Idf stands for Term frequency-Inverse document\n",
        "frequency.\n",
        "\n",
        "\n",
        "\n",
        "It assigns number to each word in vocabulary based on importance.\n",
        "\n",
        "\n",
        "Ex - if a word is very frequent occurrences in a document and is very rare in\n",
        "the entire corpus then that word is very important for the document hence\n",
        "given higher importance score.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DyYflKcWQZw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is OOV problem?"
      ],
      "metadata": {
        "id": "BpuMjYhERuhh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out-of-vocabulary (OOV) are terms that are not part of the normal lexicon found in a natural language processing environment. "
      ],
      "metadata": {
        "id": "TGdDdXWeRvir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are word embeddings?\n"
      ],
      "metadata": {
        "id": "Vu_QAUUuR9mx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word embedding is one of the most popular representation of document vocabulary. It is capable of capturing context of a word in a document, semantic and syntactic similarity, relation with other words, etc."
      ],
      "metadata": {
        "id": "jrIvpLQLSEXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain Continuous bag of words (CBOW)\n"
      ],
      "metadata": {
        "id": "juPPxLzKS5Oj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CBOW model tries to understand the context of the words and takes this as input. It then tries to predict words that are contextually accurate. Let us consider an example for understanding this. Consider the sentence: ‘It is a pleasant day’ and the word ‘pleasant’ goes as input to the neural network. We are trying to predict the word ‘day’ here. We will use the one-hot encoding for the input words and measure the error rates with the one-hot encoded target word. Doing this will help us predict the output based on the word with least error. "
      ],
      "metadata": {
        "id": "ho-Ds9UeSXCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain SkipGram\n"
      ],
      "metadata": {
        "id": "kqh-efHfToX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skip-Gram model, like all the other word2vec models, uses a trick which is also used in a lot of other Machine Learning algorithms. Since we don’t have the labels associated with the words, learning word embeddings is not an example of supervised learning. This is semi-supervised learning because we don’t have the direct labels associated with the words but we use the neighboring words (of a context word in a sentence) as the labels."
      ],
      "metadata": {
        "id": "nmLZDxh1S1KL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain Glove Embeddings.\n"
      ],
      "metadata": {
        "id": "xEB6OzXATsNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GloVe Embeddings are a type of word embedding that encode the co-occurrence probability ratio between two words as vector differences. GloVe uses a weighted least squares objective J![EMBEDDING.png](data:image/png;base64,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) that minimizes the difference between the dot product of the vectors of two words and the logarithm of their number of co-occurrences:\n",
        "\n"
      ],
      "metadata": {
        "id": "uexVLxHqT9Xk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXRerBWXMmBU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}